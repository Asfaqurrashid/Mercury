{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14shPre2R4EsDJ-HZMX3QPJhaiFG41w2P",
      "authorship_tag": "ABX9TyN16llD92KymZjrjoR/Yw+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asfaqurrashid/Mercury/blob/master/Mercury.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Collab Projects/Crop_recommendation.csv\")\n",
        "\n",
        "# Split features and label\n",
        "X = df.drop(\"label\", axis=1)  # features: N, P, K, temperature, etc.\n",
        "y = df[\"label\"]               # target: crop names like 'tomato', 'rice', etc.\n",
        "\n",
        "# Encode label (convert string crop names to numbers)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split dataset (60% training, 40% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, random_state=42\n",
        ")\n",
        "X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "j5q0W0V2Z2rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(64, input_dim=X.shape[1], activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "0Sm-4JDy0P0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqLkwrar0eYF",
        "outputId": "b0844de6-785d-4c92-ea11-ab7fef063201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1950 - loss: 9.0797 - val_accuracy: 0.6439 - val_loss: 1.0550\n",
            "Epoch 2/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.7641 - val_accuracy: 0.8598 - val_loss: 0.4998\n",
            "Epoch 3/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.4144 - val_accuracy: 0.8598 - val_loss: 0.3999\n",
            "Epoch 4/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3526 - val_accuracy: 0.9015 - val_loss: 0.3124\n",
            "Epoch 5/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2792 - val_accuracy: 0.8674 - val_loss: 0.3450\n",
            "Epoch 6/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2694 - val_accuracy: 0.9470 - val_loss: 0.1852\n",
            "Epoch 7/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.1901 - val_accuracy: 0.9356 - val_loss: 0.1758\n",
            "Epoch 8/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2498 - val_accuracy: 0.9280 - val_loss: 0.1955\n",
            "Epoch 9/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1841 - val_accuracy: 0.9356 - val_loss: 0.1919\n",
            "Epoch 10/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.1986 - val_accuracy: 0.9242 - val_loss: 0.2336\n",
            "Epoch 11/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2342 - val_accuracy: 0.9053 - val_loss: 0.2295\n",
            "Epoch 12/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2331 - val_accuracy: 0.9318 - val_loss: 0.2694\n",
            "Epoch 13/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1538 - val_accuracy: 0.9583 - val_loss: 0.1379\n",
            "Epoch 14/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1788 - val_accuracy: 0.9167 - val_loss: 0.2473\n",
            "Epoch 15/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2114 - val_accuracy: 0.9356 - val_loss: 0.1747\n",
            "Epoch 16/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1885 - val_accuracy: 0.9394 - val_loss: 0.1767\n",
            "Epoch 17/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1481 - val_accuracy: 0.9356 - val_loss: 0.1688\n",
            "Epoch 18/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1616 - val_accuracy: 0.9470 - val_loss: 0.1432\n",
            "Epoch 19/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1226 - val_accuracy: 0.9356 - val_loss: 0.1491\n",
            "Epoch 20/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1099 - val_accuracy: 0.9242 - val_loss: 0.2640\n",
            "Epoch 21/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.1143 - val_accuracy: 0.8598 - val_loss: 0.5191\n",
            "Epoch 22/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.3012 - val_accuracy: 0.9773 - val_loss: 0.0761\n",
            "Epoch 23/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1305 - val_accuracy: 0.9242 - val_loss: 0.2116\n",
            "Epoch 24/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1016 - val_accuracy: 0.9432 - val_loss: 0.1248\n",
            "Epoch 25/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1044 - val_accuracy: 0.9659 - val_loss: 0.0677\n",
            "Epoch 26/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1133 - val_accuracy: 0.9356 - val_loss: 0.1592\n",
            "Epoch 27/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1363 - val_accuracy: 0.9394 - val_loss: 0.1415\n",
            "Epoch 28/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1035 - val_accuracy: 0.9356 - val_loss: 0.1603\n",
            "Epoch 29/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.1116 - val_accuracy: 0.9735 - val_loss: 0.0914\n",
            "Epoch 30/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0980 - val_accuracy: 0.9205 - val_loss: 0.3934\n",
            "Epoch 31/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1559 - val_accuracy: 0.8977 - val_loss: 0.4829\n",
            "Epoch 32/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1582 - val_accuracy: 0.9470 - val_loss: 0.1246\n",
            "Epoch 33/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1664 - val_accuracy: 0.9697 - val_loss: 0.0784\n",
            "Epoch 34/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.0789 - val_accuracy: 0.9394 - val_loss: 0.1392\n",
            "Epoch 35/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.0992 - val_accuracy: 0.9432 - val_loss: 0.1448\n",
            "Epoch 36/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9531 - loss: 0.1223 - val_accuracy: 0.9583 - val_loss: 0.1359\n",
            "Epoch 37/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0880 - val_accuracy: 0.9583 - val_loss: 0.1106\n",
            "Epoch 38/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0702 - val_accuracy: 0.9583 - val_loss: 0.1078\n",
            "Epoch 39/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0750 - val_accuracy: 0.9697 - val_loss: 0.0689\n",
            "Epoch 40/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.0874 - val_accuracy: 0.9545 - val_loss: 0.1147\n",
            "Epoch 41/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0742 - val_accuracy: 0.9773 - val_loss: 0.0814\n",
            "Epoch 42/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.0929 - val_accuracy: 0.9697 - val_loss: 0.0861\n",
            "Epoch 43/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1251 - val_accuracy: 0.9583 - val_loss: 0.1109\n",
            "Epoch 44/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0757 - val_accuracy: 0.9735 - val_loss: 0.0669\n",
            "Epoch 45/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0957 - val_accuracy: 0.9545 - val_loss: 0.1221\n",
            "Epoch 46/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0724 - val_accuracy: 0.8750 - val_loss: 0.6964\n",
            "Epoch 47/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2093 - val_accuracy: 0.9659 - val_loss: 0.0991\n",
            "Epoch 48/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1056 - val_accuracy: 0.9735 - val_loss: 0.0883\n",
            "Epoch 49/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0757 - val_accuracy: 0.9508 - val_loss: 0.1081\n",
            "Epoch 50/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1234 - val_accuracy: 0.9773 - val_loss: 0.0894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79367d2a1350>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-h-yFAB04F8",
        "outputId": "f9fbe056-0101-4c17-92b2-03a918688777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1429\n",
            "Test Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"crop_model.keras\")\n"
      ],
      "metadata": {
        "id": "CuA1YMUh04za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "sample = np.array([[90, 42, 43, 20.5, 82.0, 6.5, 190.0]])  # example input\n",
        "prediction = model.predict(sample)\n",
        "predicted_label = le.inverse_transform([prediction.argmax()])[0]\n",
        "\n",
        "print(\"Predicted crop:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_NzcXEp1nvq",
        "outputId": "1cd1c9f3-6f68-49ec-f99b-cfad65c41bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "Predicted crop: jute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Predict class probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Get predicted class indices\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Decode both actual and predicted labels back to original crop names\n",
        "y_actual_labels = le.inverse_transform(y_test)\n",
        "y_predicted_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "# Display side-by-side comparison for first 20 predictions\n",
        "print(f\"{'Actual':<15}{'Predicted':<15}\")\n",
        "print(\"-\" * 30)\n",
        "for actual, predicted in zip(y_actual_labels[:200], y_predicted_labels[:200]):\n",
        "    print(f\"{actual:<15}{predicted:<15}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leeSE-WS21OK",
        "outputId": "b5b6dda5-80e4-4a68-ed4b-700e8499a5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Actual         Predicted      \n",
            "------------------------------\n",
            "muskmelon      muskmelon      \n",
            "watermelon     watermelon     \n",
            "papaya         papaya         \n",
            "papaya         papaya         \n",
            "apple          apple          \n",
            "mango          mango          \n",
            "apple          apple          \n",
            "mothbeans      mothbeans      \n",
            "mungbean       mungbean       \n",
            "lentil         lentil         \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "jute           jute           \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "apple          apple          \n",
            "maize          cotton         \n",
            "papaya         papaya         \n",
            "muskmelon      muskmelon      \n",
            "coffee         coffee         \n",
            "papaya         papaya         \n",
            "orange         orange         \n",
            "papaya         papaya         \n",
            "chickpea       chickpea       \n",
            "jute           jute           \n",
            "mungbean       mungbean       \n",
            "orange         orange         \n",
            "pigeonpeas     pigeonpeas     \n",
            "rice           jute           \n",
            "pomegranate    pomegranate    \n",
            "mothbeans      mothbeans      \n",
            "jute           jute           \n",
            "lentil         lentil         \n",
            "jute           jute           \n",
            "blackgram      blackgram      \n",
            "jute           jute           \n",
            "chickpea       chickpea       \n",
            "chickpea       chickpea       \n",
            "kidneybeans    kidneybeans    \n",
            "papaya         papaya         \n",
            "mango          mango          \n",
            "blackgram      blackgram      \n",
            "maize          maize          \n",
            "mungbean       mungbean       \n",
            "maize          maize          \n",
            "pigeonpeas     pigeonpeas     \n",
            "coconut        coconut        \n",
            "muskmelon      muskmelon      \n",
            "maize          maize          \n",
            "blackgram      blackgram      \n",
            "coffee         coffee         \n",
            "grapes         grapes         \n",
            "mungbean       mungbean       \n",
            "coffee         coffee         \n",
            "kidneybeans    kidneybeans    \n",
            "cotton         cotton         \n",
            "apple          apple          \n",
            "banana         banana         \n",
            "blackgram      blackgram      \n",
            "watermelon     watermelon     \n",
            "coconut        coconut        \n",
            "lentil         lentil         \n",
            "orange         orange         \n",
            "papaya         papaya         \n",
            "pigeonpeas     blackgram      \n",
            "orange         orange         \n",
            "rice           rice           \n",
            "muskmelon      muskmelon      \n",
            "pigeonpeas     pigeonpeas     \n",
            "muskmelon      muskmelon      \n",
            "coconut        coconut        \n",
            "jute           jute           \n",
            "banana         banana         \n",
            "blackgram      blackgram      \n",
            "papaya         papaya         \n",
            "banana         banana         \n",
            "cotton         cotton         \n",
            "watermelon     watermelon     \n",
            "orange         orange         \n",
            "coffee         coffee         \n",
            "chickpea       chickpea       \n",
            "rice           jute           \n",
            "mothbeans      mothbeans      \n",
            "orange         orange         \n",
            "mango          mango          \n",
            "coffee         coffee         \n",
            "mothbeans      blackgram      \n",
            "blackgram      blackgram      \n",
            "pomegranate    pomegranate    \n",
            "maize          maize          \n",
            "mothbeans      mothbeans      \n",
            "cotton         cotton         \n",
            "papaya         papaya         \n",
            "pigeonpeas     pigeonpeas     \n",
            "mothbeans      mothbeans      \n",
            "kidneybeans    kidneybeans    \n",
            "coffee         coffee         \n",
            "blackgram      blackgram      \n",
            "lentil         lentil         \n",
            "coconut        coconut        \n",
            "rice           jute           \n",
            "orange         orange         \n",
            "muskmelon      muskmelon      \n",
            "watermelon     watermelon     \n",
            "kidneybeans    kidneybeans    \n",
            "watermelon     watermelon     \n",
            "banana         banana         \n",
            "pigeonpeas     pigeonpeas     \n",
            "mothbeans      mothbeans      \n",
            "banana         banana         \n",
            "jute           jute           \n",
            "cotton         cotton         \n",
            "pomegranate    pomegranate    \n",
            "pigeonpeas     pigeonpeas     \n",
            "chickpea       chickpea       \n",
            "maize          maize          \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "rice           rice           \n",
            "pigeonpeas     pigeonpeas     \n",
            "grapes         grapes         \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "chickpea       chickpea       \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "banana         banana         \n",
            "mothbeans      mothbeans      \n",
            "banana         banana         \n",
            "kidneybeans    kidneybeans    \n",
            "pomegranate    pomegranate    \n",
            "chickpea       chickpea       \n",
            "coconut        coconut        \n",
            "orange         orange         \n",
            "pigeonpeas     pigeonpeas     \n",
            "banana         banana         \n",
            "banana         banana         \n",
            "apple          apple          \n",
            "kidneybeans    kidneybeans    \n",
            "muskmelon      muskmelon      \n",
            "mungbean       mungbean       \n",
            "mothbeans      mothbeans      \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "apple          apple          \n",
            "coconut        coconut        \n",
            "kidneybeans    kidneybeans    \n",
            "mothbeans      blackgram      \n",
            "mungbean       mungbean       \n",
            "lentil         lentil         \n",
            "watermelon     watermelon     \n",
            "mungbean       mungbean       \n",
            "pigeonpeas     blackgram      \n",
            "pigeonpeas     blackgram      \n",
            "pigeonpeas     pigeonpeas     \n",
            "kidneybeans    kidneybeans    \n",
            "maize          maize          \n",
            "jute           jute           \n",
            "chickpea       chickpea       \n",
            "apple          apple          \n",
            "orange         orange         \n",
            "cotton         cotton         \n",
            "rice           rice           \n",
            "coconut        coconut        \n",
            "grapes         grapes         \n",
            "lentil         lentil         \n",
            "watermelon     watermelon     \n",
            "grapes         grapes         \n",
            "grapes         grapes         \n",
            "blackgram      blackgram      \n",
            "pomegranate    pomegranate    \n",
            "chickpea       chickpea       \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "lentil         lentil         \n",
            "grapes         grapes         \n",
            "watermelon     watermelon     \n",
            "jute           jute           \n",
            "coffee         coffee         \n",
            "coffee         coffee         \n",
            "kidneybeans    kidneybeans    \n",
            "jute           jute           \n",
            "mothbeans      mothbeans      \n",
            "kidneybeans    kidneybeans    \n",
            "banana         banana         \n",
            "kidneybeans    pigeonpeas     \n",
            "coconut        coconut        \n",
            "papaya         papaya         \n",
            "papaya         papaya         \n",
            "mungbean       mungbean       \n",
            "mango          mango          \n",
            "pomegranate    pomegranate    \n",
            "watermelon     watermelon     \n",
            "kidneybeans    kidneybeans    \n",
            "maize          maize          \n",
            "apple          apple          \n",
            "blackgram      blackgram      \n",
            "chickpea       chickpea       \n"
          ]
        }
      ]
    }
  ]
}