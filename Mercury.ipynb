{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14shPre2R4EsDJ-HZMX3QPJhaiFG41w2P",
      "authorship_tag": "ABX9TyPoqwQdpIHMZ/PSPLKwJ8/I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Collab Projects/Crop_recommendation.csv\")\n",
        "\n",
        "\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, random_state=42\n",
        ")\n",
        "X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "j5q0W0V2Z2rF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d444e01d-8925-4f16-befd-7f0fbebda805"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        N    P    K  temperature   humidity        ph    rainfall\n",
              " 208    42   62   75    18.179123  18.904269  7.010571   81.849975\n",
              " 1641    0   23   15    22.566642  93.374889  7.598729  109.858575\n",
              " 881     9   56   17    26.137083  66.772921  6.261938   46.482807\n",
              " 720    58   71   15    27.825928  67.586188  6.919244   74.012297\n",
              " 1017  109   79   45    27.667528  79.685428  6.490074  108.664640\n",
              " ...   ...  ...  ...          ...        ...       ...         ...\n",
              " 1638   10    5    5    21.213070  91.353492  7.817846  112.983436\n",
              " 1095  108   94   47    27.359116  84.546250  6.387431   90.812505\n",
              " 1130   11   36   31    27.920633  51.779659  6.475449  100.258567\n",
              " 1294   11  124  204    13.429886  80.066340  6.361141   71.400430\n",
              " 860    32   78   22    23.970814  62.355576  7.007038   53.409060\n",
              " \n",
              " [1320 rows x 7 columns],\n",
              "         N    P    K  temperature   humidity        ph    rainfall\n",
              " 1451  101   17   47    29.494014  94.729813  6.185053   26.308209\n",
              " 1334   98    8   51    26.179346  86.522581  6.259336   49.430510\n",
              " 1761   59   62   49    43.360515  93.351916  6.941497  114.778071\n",
              " 1735   44   60   55    34.280461  90.555616  6.825371   98.540477\n",
              " 1576   30  137  200    22.914300  90.704756  5.603413  118.604465\n",
              " ...   ...  ...  ...          ...        ...       ...         ...\n",
              " 1839   14   21   35    29.525014  91.911853  6.121006  194.310027\n",
              " 236    57   58   77    18.726494  17.584064  7.978997   81.201765\n",
              " 551    22   42   22    25.542491  56.966408  7.887659   48.467970\n",
              " 520    11   44   17    26.340433  55.591604  8.016211   35.105120\n",
              " 1261   22  133  201    23.819957  80.122116  6.002996   67.273986\n",
              " \n",
              " [880 rows x 7 columns],\n",
              " array([ 3, 16, 10, ..., 12,  7, 10]),\n",
              " array([15, 21, 17, 17,  0, 12,  0, 13, 14, 10,  2,  4, 19,  8,  4, 19,  0,\n",
              "        11, 17, 15,  5, 17, 16, 17,  3,  8, 14, 16, 18, 20, 19, 13,  8, 10,\n",
              "         8,  2,  8,  3,  3,  9, 17, 12,  2, 11, 14, 11, 18,  4, 15, 11,  2,\n",
              "         5,  7, 14,  5,  9,  6,  0,  1,  2, 21,  4, 10, 16, 17, 18, 16, 20,\n",
              "        15, 18, 15,  4,  8,  1,  2, 17,  1,  6, 21, 16,  5,  3, 20, 13, 16,\n",
              "        12,  5, 13,  2, 19, 11, 13,  6, 17, 18, 13,  9,  5,  2, 10,  4, 20,\n",
              "        16, 15, 21,  9, 21,  1, 18, 13,  1,  8,  6, 19, 18,  3, 11,  4, 19,\n",
              "        20, 18,  7,  2,  4,  3,  2,  4, 11,  1, 13,  1,  9, 19,  3,  4, 16,\n",
              "        18,  1,  1,  0,  9, 15, 14, 13,  4, 11,  0,  4,  9, 13, 14, 10, 21,\n",
              "        14, 18, 18, 18,  9, 11,  8,  3,  0, 16,  6, 20,  4,  7, 10, 21,  7,\n",
              "         7,  2, 19,  3,  4, 11, 10,  7, 21,  8,  5,  5,  9,  8, 13,  9,  1,\n",
              "         9,  4, 17, 17, 14, 12, 19, 21,  9, 11,  0,  2,  3,  7,  7,  1,  6,\n",
              "        20, 19, 14,  1,  8, 14, 11,  3,  3,  3,  0, 20,  9, 17,  5,  2,  9,\n",
              "        12, 12,  4, 17,  0,  3, 19,  3, 15,  0, 15, 15, 12, 12,  6,  4, 19,\n",
              "        20, 15,  5, 17, 13, 11, 12, 15, 18, 14,  5,  7,  4,  6, 18, 20,  0,\n",
              "        19,  5,  3,  6,  8, 12,  1, 17,  0,  3, 20, 18, 13, 14,  8, 19,  7,\n",
              "        13,  8, 11,  4, 11,  3,  1, 20,  4,  8, 12, 15,  0,  1, 18,  2, 16,\n",
              "         3, 21,  1,  0,  3,  5, 18, 16,  0,  4, 17, 21, 13, 17,  3, 19,  3,\n",
              "        17, 10,  0, 19,  3, 12,  3, 19, 21,  9, 14, 15, 21,  9, 15, 12, 20,\n",
              "         2,  3,  1,  2, 18, 17, 18, 14,  4,  6,  7,  0, 10,  1,  8,  0, 19,\n",
              "         0, 14, 15,  5,  5, 18,  8,  9,  1, 11,  8, 11, 18, 12,  9, 19, 21,\n",
              "         2, 11, 20, 13,  9, 12,  6, 17, 13,  6, 14, 16,  8,  2, 14,  5,  1,\n",
              "        18, 17,  0, 19, 11, 12,  4,  0, 10,  8, 13, 10,  4,  2,  8, 14,  6,\n",
              "        21,  0,  7,  4,  7, 21, 20, 12, 12,  5, 19,  1,  7,  8, 16,  6, 12,\n",
              "        17, 15, 13,  8,  3, 13, 19, 21, 13,  6, 17, 21, 13, 20,  4, 13, 13,\n",
              "        11, 20, 11,  4, 16, 19,  9, 21, 14,  2, 20, 20,  6,  6, 18, 16,  2,\n",
              "        10,  1, 12, 11,  0, 19, 12,  6, 14, 18,  3,  0,  5, 18,  8,  8,  8,\n",
              "        17, 10,  7, 20, 16, 14, 12,  9,  7, 14, 16, 18,  1, 20, 18, 19,  5,\n",
              "        15,  2, 17, 17, 19,  9,  3, 14, 14, 12, 18, 15, 12, 13, 18, 15, 20,\n",
              "        19, 15, 18,  0, 14, 20,  9,  0, 20, 12, 17, 13,  6, 19, 18, 17, 10,\n",
              "        11,  3, 15,  6,  9,  3, 14,  5,  5, 16, 21, 16,  7,  5, 18, 12,  0,\n",
              "        12, 19,  5, 18,  5,  7,  6, 19, 17,  0,  2, 18, 21, 17,  2,  7, 10,\n",
              "        20,  5, 17,  3,  5,  8, 13, 19, 17, 18,  0,  9, 16, 13, 20, 14, 21,\n",
              "        19,  4,  4,  8, 19,  9, 13,  8,  9, 20, 10, 17, 19, 16,  3,  8, 19,\n",
              "         6, 13, 14,  7, 14, 10,  6,  9, 12, 15,  9, 16, 18, 11,  8,  5,  6,\n",
              "        11, 10,  9, 19, 17, 20, 18, 15, 14,  9, 11,  8,  9,  3,  6, 13,  0,\n",
              "        17, 19,  6, 12,  7, 12,  5,  5,  6, 13,  4,  4,  4,  0, 16, 12, 12,\n",
              "        16,  1,  0,  7,  2,  9,  7,  6, 10,  1, 13,  0,  8, 10,  5, 16, 10,\n",
              "         2,  1,  9, 19,  8, 17, 10,  4,  9,  9, 13, 17,  3, 21, 12, 12, 11,\n",
              "         1, 20, 13,  0,  9, 10,  3,  9,  6, 18,  3,  3, 15,  7, 10,  0, 14,\n",
              "        18,  3,  6,  3, 18,  7,  0,  9,  2,  2, 18,  5, 10,  6, 16, 19, 16,\n",
              "         0, 13,  5, 10, 11, 11, 19, 15, 11, 14,  8, 11, 10,  3, 14,  4,  4,\n",
              "         6,  9,  3, 13,  5,  2,  6, 11, 13, 10,  9,  1, 21,  7, 10,  2, 20,\n",
              "        19, 12,  4,  6, 13, 14, 10,  7, 18,  1, 11,  1, 15,  7, 10, 21,  1,\n",
              "         0, 12, 13,  1, 16, 16,  0,  8, 12, 20,  7,  3, 17, 11, 15, 17,  8,\n",
              "        11,  0, 18,  5,  0,  4, 10, 12, 15,  8,  6, 16, 19,  2, 20, 13, 15,\n",
              "        21, 10, 18,  7, 13, 19,  8, 21,  5,  8,  0,  8, 16, 12,  9, 21, 18,\n",
              "         6, 16, 21, 15,  6,  9,  3,  2, 10,  8, 19, 15,  4,  1, 15,  1, 11,\n",
              "        10,  7,  5,  3, 14, 10,  2,  1,  8, 12, 13, 13, 21,  2, 16, 21,  0,\n",
              "         0,  5,  2, 21,  6, 11,  2,  7,  3,  7,  4,  1, 14, 13,  6,  9,  6,\n",
              "        21,  4,  7,  0, 17, 20, 21,  5,  0,  7, 12,  4, 10, 14, 15,  4, 16,\n",
              "        15, 16, 18,  0,  3,  2,  5,  9,  4,  3, 13, 13,  7]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(64, input_dim=X.shape[1], activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "0Sm-4JDy0P0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqLkwrar0eYF",
        "outputId": "b0844de6-785d-4c92-ea11-ab7fef063201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1950 - loss: 9.0797 - val_accuracy: 0.6439 - val_loss: 1.0550\n",
            "Epoch 2/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.7641 - val_accuracy: 0.8598 - val_loss: 0.4998\n",
            "Epoch 3/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.4144 - val_accuracy: 0.8598 - val_loss: 0.3999\n",
            "Epoch 4/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3526 - val_accuracy: 0.9015 - val_loss: 0.3124\n",
            "Epoch 5/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2792 - val_accuracy: 0.8674 - val_loss: 0.3450\n",
            "Epoch 6/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2694 - val_accuracy: 0.9470 - val_loss: 0.1852\n",
            "Epoch 7/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.1901 - val_accuracy: 0.9356 - val_loss: 0.1758\n",
            "Epoch 8/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2498 - val_accuracy: 0.9280 - val_loss: 0.1955\n",
            "Epoch 9/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1841 - val_accuracy: 0.9356 - val_loss: 0.1919\n",
            "Epoch 10/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.1986 - val_accuracy: 0.9242 - val_loss: 0.2336\n",
            "Epoch 11/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2342 - val_accuracy: 0.9053 - val_loss: 0.2295\n",
            "Epoch 12/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2331 - val_accuracy: 0.9318 - val_loss: 0.2694\n",
            "Epoch 13/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1538 - val_accuracy: 0.9583 - val_loss: 0.1379\n",
            "Epoch 14/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1788 - val_accuracy: 0.9167 - val_loss: 0.2473\n",
            "Epoch 15/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2114 - val_accuracy: 0.9356 - val_loss: 0.1747\n",
            "Epoch 16/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1885 - val_accuracy: 0.9394 - val_loss: 0.1767\n",
            "Epoch 17/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1481 - val_accuracy: 0.9356 - val_loss: 0.1688\n",
            "Epoch 18/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1616 - val_accuracy: 0.9470 - val_loss: 0.1432\n",
            "Epoch 19/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1226 - val_accuracy: 0.9356 - val_loss: 0.1491\n",
            "Epoch 20/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1099 - val_accuracy: 0.9242 - val_loss: 0.2640\n",
            "Epoch 21/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.1143 - val_accuracy: 0.8598 - val_loss: 0.5191\n",
            "Epoch 22/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9302 - loss: 0.3012 - val_accuracy: 0.9773 - val_loss: 0.0761\n",
            "Epoch 23/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1305 - val_accuracy: 0.9242 - val_loss: 0.2116\n",
            "Epoch 24/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1016 - val_accuracy: 0.9432 - val_loss: 0.1248\n",
            "Epoch 25/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1044 - val_accuracy: 0.9659 - val_loss: 0.0677\n",
            "Epoch 26/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1133 - val_accuracy: 0.9356 - val_loss: 0.1592\n",
            "Epoch 27/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1363 - val_accuracy: 0.9394 - val_loss: 0.1415\n",
            "Epoch 28/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1035 - val_accuracy: 0.9356 - val_loss: 0.1603\n",
            "Epoch 29/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.1116 - val_accuracy: 0.9735 - val_loss: 0.0914\n",
            "Epoch 30/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.0980 - val_accuracy: 0.9205 - val_loss: 0.3934\n",
            "Epoch 31/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1559 - val_accuracy: 0.8977 - val_loss: 0.4829\n",
            "Epoch 32/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1582 - val_accuracy: 0.9470 - val_loss: 0.1246\n",
            "Epoch 33/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.1664 - val_accuracy: 0.9697 - val_loss: 0.0784\n",
            "Epoch 34/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.0789 - val_accuracy: 0.9394 - val_loss: 0.1392\n",
            "Epoch 35/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.0992 - val_accuracy: 0.9432 - val_loss: 0.1448\n",
            "Epoch 36/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9531 - loss: 0.1223 - val_accuracy: 0.9583 - val_loss: 0.1359\n",
            "Epoch 37/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0880 - val_accuracy: 0.9583 - val_loss: 0.1106\n",
            "Epoch 38/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0702 - val_accuracy: 0.9583 - val_loss: 0.1078\n",
            "Epoch 39/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0750 - val_accuracy: 0.9697 - val_loss: 0.0689\n",
            "Epoch 40/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.0874 - val_accuracy: 0.9545 - val_loss: 0.1147\n",
            "Epoch 41/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0742 - val_accuracy: 0.9773 - val_loss: 0.0814\n",
            "Epoch 42/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.0929 - val_accuracy: 0.9697 - val_loss: 0.0861\n",
            "Epoch 43/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.1251 - val_accuracy: 0.9583 - val_loss: 0.1109\n",
            "Epoch 44/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0757 - val_accuracy: 0.9735 - val_loss: 0.0669\n",
            "Epoch 45/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0957 - val_accuracy: 0.9545 - val_loss: 0.1221\n",
            "Epoch 46/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0724 - val_accuracy: 0.8750 - val_loss: 0.6964\n",
            "Epoch 47/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2093 - val_accuracy: 0.9659 - val_loss: 0.0991\n",
            "Epoch 48/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1056 - val_accuracy: 0.9735 - val_loss: 0.0883\n",
            "Epoch 49/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0757 - val_accuracy: 0.9508 - val_loss: 0.1081\n",
            "Epoch 50/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1234 - val_accuracy: 0.9773 - val_loss: 0.0894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79367d2a1350>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-h-yFAB04F8",
        "outputId": "f9fbe056-0101-4c17-92b2-03a918688777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1429\n",
            "Test Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"crop_model.keras\")\n"
      ],
      "metadata": {
        "id": "CuA1YMUh04za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "sample = np.array([[90, 42, 43, 20.5, 82.0, 6.5, 190.0]])  # example input\n",
        "prediction = model.predict(sample)\n",
        "predicted_label = le.inverse_transform([prediction.argmax()])[0]\n",
        "\n",
        "print(\"Predicted crop:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_NzcXEp1nvq",
        "outputId": "1cd1c9f3-6f68-49ec-f99b-cfad65c41bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "Predicted crop: jute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_actual_labels = le.inverse_transform(y_test)\n",
        "y_predicted_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "print(f\"{'Actual':<15}{'Predicted':<15}\")\n",
        "print(\"-\" * 30)\n",
        "for actual, predicted in zip(y_actual_labels[:200], y_predicted_labels[:200]):\n",
        "    print(f\"{actual:<15}{predicted:<15}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leeSE-WS21OK",
        "outputId": "b5b6dda5-80e4-4a68-ed4b-700e8499a5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Actual         Predicted      \n",
            "------------------------------\n",
            "muskmelon      muskmelon      \n",
            "watermelon     watermelon     \n",
            "papaya         papaya         \n",
            "papaya         papaya         \n",
            "apple          apple          \n",
            "mango          mango          \n",
            "apple          apple          \n",
            "mothbeans      mothbeans      \n",
            "mungbean       mungbean       \n",
            "lentil         lentil         \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "jute           jute           \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "apple          apple          \n",
            "maize          cotton         \n",
            "papaya         papaya         \n",
            "muskmelon      muskmelon      \n",
            "coffee         coffee         \n",
            "papaya         papaya         \n",
            "orange         orange         \n",
            "papaya         papaya         \n",
            "chickpea       chickpea       \n",
            "jute           jute           \n",
            "mungbean       mungbean       \n",
            "orange         orange         \n",
            "pigeonpeas     pigeonpeas     \n",
            "rice           jute           \n",
            "pomegranate    pomegranate    \n",
            "mothbeans      mothbeans      \n",
            "jute           jute           \n",
            "lentil         lentil         \n",
            "jute           jute           \n",
            "blackgram      blackgram      \n",
            "jute           jute           \n",
            "chickpea       chickpea       \n",
            "chickpea       chickpea       \n",
            "kidneybeans    kidneybeans    \n",
            "papaya         papaya         \n",
            "mango          mango          \n",
            "blackgram      blackgram      \n",
            "maize          maize          \n",
            "mungbean       mungbean       \n",
            "maize          maize          \n",
            "pigeonpeas     pigeonpeas     \n",
            "coconut        coconut        \n",
            "muskmelon      muskmelon      \n",
            "maize          maize          \n",
            "blackgram      blackgram      \n",
            "coffee         coffee         \n",
            "grapes         grapes         \n",
            "mungbean       mungbean       \n",
            "coffee         coffee         \n",
            "kidneybeans    kidneybeans    \n",
            "cotton         cotton         \n",
            "apple          apple          \n",
            "banana         banana         \n",
            "blackgram      blackgram      \n",
            "watermelon     watermelon     \n",
            "coconut        coconut        \n",
            "lentil         lentil         \n",
            "orange         orange         \n",
            "papaya         papaya         \n",
            "pigeonpeas     blackgram      \n",
            "orange         orange         \n",
            "rice           rice           \n",
            "muskmelon      muskmelon      \n",
            "pigeonpeas     pigeonpeas     \n",
            "muskmelon      muskmelon      \n",
            "coconut        coconut        \n",
            "jute           jute           \n",
            "banana         banana         \n",
            "blackgram      blackgram      \n",
            "papaya         papaya         \n",
            "banana         banana         \n",
            "cotton         cotton         \n",
            "watermelon     watermelon     \n",
            "orange         orange         \n",
            "coffee         coffee         \n",
            "chickpea       chickpea       \n",
            "rice           jute           \n",
            "mothbeans      mothbeans      \n",
            "orange         orange         \n",
            "mango          mango          \n",
            "coffee         coffee         \n",
            "mothbeans      blackgram      \n",
            "blackgram      blackgram      \n",
            "pomegranate    pomegranate    \n",
            "maize          maize          \n",
            "mothbeans      mothbeans      \n",
            "cotton         cotton         \n",
            "papaya         papaya         \n",
            "pigeonpeas     pigeonpeas     \n",
            "mothbeans      mothbeans      \n",
            "kidneybeans    kidneybeans    \n",
            "coffee         coffee         \n",
            "blackgram      blackgram      \n",
            "lentil         lentil         \n",
            "coconut        coconut        \n",
            "rice           jute           \n",
            "orange         orange         \n",
            "muskmelon      muskmelon      \n",
            "watermelon     watermelon     \n",
            "kidneybeans    kidneybeans    \n",
            "watermelon     watermelon     \n",
            "banana         banana         \n",
            "pigeonpeas     pigeonpeas     \n",
            "mothbeans      mothbeans      \n",
            "banana         banana         \n",
            "jute           jute           \n",
            "cotton         cotton         \n",
            "pomegranate    pomegranate    \n",
            "pigeonpeas     pigeonpeas     \n",
            "chickpea       chickpea       \n",
            "maize          maize          \n",
            "coconut        coconut        \n",
            "pomegranate    pomegranate    \n",
            "rice           rice           \n",
            "pigeonpeas     pigeonpeas     \n",
            "grapes         grapes         \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "chickpea       chickpea       \n",
            "blackgram      blackgram      \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "banana         banana         \n",
            "mothbeans      mothbeans      \n",
            "banana         banana         \n",
            "kidneybeans    kidneybeans    \n",
            "pomegranate    pomegranate    \n",
            "chickpea       chickpea       \n",
            "coconut        coconut        \n",
            "orange         orange         \n",
            "pigeonpeas     pigeonpeas     \n",
            "banana         banana         \n",
            "banana         banana         \n",
            "apple          apple          \n",
            "kidneybeans    kidneybeans    \n",
            "muskmelon      muskmelon      \n",
            "mungbean       mungbean       \n",
            "mothbeans      mothbeans      \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "apple          apple          \n",
            "coconut        coconut        \n",
            "kidneybeans    kidneybeans    \n",
            "mothbeans      blackgram      \n",
            "mungbean       mungbean       \n",
            "lentil         lentil         \n",
            "watermelon     watermelon     \n",
            "mungbean       mungbean       \n",
            "pigeonpeas     blackgram      \n",
            "pigeonpeas     blackgram      \n",
            "pigeonpeas     pigeonpeas     \n",
            "kidneybeans    kidneybeans    \n",
            "maize          maize          \n",
            "jute           jute           \n",
            "chickpea       chickpea       \n",
            "apple          apple          \n",
            "orange         orange         \n",
            "cotton         cotton         \n",
            "rice           rice           \n",
            "coconut        coconut        \n",
            "grapes         grapes         \n",
            "lentil         lentil         \n",
            "watermelon     watermelon     \n",
            "grapes         grapes         \n",
            "grapes         grapes         \n",
            "blackgram      blackgram      \n",
            "pomegranate    pomegranate    \n",
            "chickpea       chickpea       \n",
            "coconut        coconut        \n",
            "maize          maize          \n",
            "lentil         lentil         \n",
            "grapes         grapes         \n",
            "watermelon     watermelon     \n",
            "jute           jute           \n",
            "coffee         coffee         \n",
            "coffee         coffee         \n",
            "kidneybeans    kidneybeans    \n",
            "jute           jute           \n",
            "mothbeans      mothbeans      \n",
            "kidneybeans    kidneybeans    \n",
            "banana         banana         \n",
            "kidneybeans    pigeonpeas     \n",
            "coconut        coconut        \n",
            "papaya         papaya         \n",
            "papaya         papaya         \n",
            "mungbean       mungbean       \n",
            "mango          mango          \n",
            "pomegranate    pomegranate    \n",
            "watermelon     watermelon     \n",
            "kidneybeans    kidneybeans    \n",
            "maize          maize          \n",
            "apple          apple          \n",
            "blackgram      blackgram      \n",
            "chickpea       chickpea       \n"
          ]
        }
      ]
    }
  ]
}